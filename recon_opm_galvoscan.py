#!/usr/bin/env python

'''
Galvo scanning OPM post-processing using numpy, numba, skimage, pyimagej, and npy2bdv.
Orthgonal interpolation method adapted from original description by Vincent Maioli (http://doi.org/10.25560/68022)

Last updated: Shepherd 04/21
'''

# imports
import numpy as np
from pathlib import Path
from pycromanager import Dataset
import npy2bdv
import sys
import argparse
from skimage.measure import block_reduce
import skimage.io
from image_post_processing import deskew
import dask.array as da
import glob
from itertools import compress
from itertools import product
import data_io

# parse experimental directory, load data, perform orthogonal deskew, and save as BDV H5 file
def main(argv):

    # parse command line arguments
    # TODO: output directory option not implemented
    parser = argparse.ArgumentParser(description="Process raw OPM data.")
    parser.add_argument("-i", "--ipath", type=str, nargs="+", help="supply the directories to be processed")
    parser.add_argument("-o", "--opath", type=str, nargs="+",
                        help="supply the output directories where data will be saved")
    parser.add_argument("-a", "--acq", type=int, choices=[0, 1], help="0: pycromanager (DEFAULT), 1: hcimage")
    parser.add_argument("-d", "--decon", type=bool, default=False,
                        help="0: no deconvolution (DEFAULT), 1: deconvolution")
    parser.add_argument("-f", "--flatfield", type=bool, default=False, help="0: no flat-field (DEFAULT), 1: flat-field")
    args = parser.parse_args()

    acq_type = args.acq
    decon_flag = args.decon
    flatfield_flag = args.flatfield
    input_dir_strings = args.ipath
    output_dir_strings = args.opath

    for ii, input_dir_string in enumerate(input_dir_strings):
        print("Processing directory %d/%d" % (ii + 1, len(input_dir_strings)))
        # Load data
        # Data must be generated by QI2lab pycromanager control code
        # https://www.github.com/qi2lab/OPM/

        # https://docs.python.org/3/library/pathlib.html
        # Create Path object to directory
        input_dir_path=Path(input_dir_string)

        # create parameter array from scan parameters saved by acquisition code
        # [timepoints, channels, scan positions, y pixels, x pixels, theta, stage move distance, camera pixel size]
        # units are [degrees,nm,nm]
        if acq_type==0:
            # df_metadata = pd.read_csv(input_dir_path.resolve().parents[0] / 'scan_metadata.csv')
            df_metadata = data_io.read_metadata(input_dir_path.resolve().parents[0] / 'scan_metadata.csv')
        else:
            # df_metadata = pd.read_csv(input_dir_path / 'scan_metadata.csv')
            df_metadata = data_io.read_metadata(input_dir_path / 'scan_metadata.csv')

        root_name = df_metadata['root_name']
        scan_type = df_metadata['scan_type']
        theta = df_metadata['theta']
        scan_step = df_metadata['scan_step']
        pixel_size = df_metadata['pixel_size']
        num_t = df_metadata['num_t']
        num_y = df_metadata['num_y']
        num_z  = df_metadata['num_z']
        num_ch = df_metadata['num_ch']
        num_images = df_metadata['scan_axis_positions']
        y_pixels = df_metadata['y_pixels']
        x_pixels = df_metadata['x_pixels']
        chan_405_active = df_metadata['405_active']
        chan_488_active = df_metadata['488_active']
        chan_561_active = df_metadata['561_active']
        chan_635_active = df_metadata['635_active']
        chan_730_active = df_metadata['730_active']
        active_channels = [chan_405_active,chan_488_active,chan_561_active,chan_635_active,chan_730_active]
        channel_idxs = [0,1,2,3,4]
        channels_in_data = list(compress(channel_idxs, active_channels))
        n_active_channels = len(channels_in_data)
        if not (num_ch == n_active_channels):
            print('Channel setup error. Check metatdata file and directory names.')
            sys.exit()

        # load data
        if acq_type == 0:
            dataset = Dataset(str(input_dir_path))
            dask_array_raw = dataset.as_array()
            dask_array_raw = np.squeeze(dask_array_raw)

            # check which axes match experimental metadata
            dataset_shape = dask_array_raw.shape
            for i in range(len(dataset_shape)):
                if not(num_t == 1) and (dataset_shape[i] == num_t):
                    timepoint_axis = i
                elif not(num_ch == 1) and (dataset_shape[i] == num_ch):
                    channel_axis = i
                elif dataset_shape[i] == num_images:
                    scan_axis = i
                elif dataset_shape[i] == y_pixels:
                    y_axis = i
                elif dataset_shape[i] == x_pixels:
                    x_axis = i
                else:
                    raise ValueError("Could not identify dataset axis %d with size %d" % (i, dataset_shape[i]))


            # reorder dask array to [time,channel,scan,y,x]
            if len(dataset_shape) == 5:
                dask_array = da.moveaxis(dask_array_raw,[timepoint_axis,channel_axis,scan_axis,y_axis,x_axis],[0,1,2,3,4])
            elif len(dataset_shape) == 4:
                if (num_ch==1):
                    dask_array = da.moveaxis(dask_array_raw,[timepoint_axis,scan_axis,y_axis,x_axis],[0,1,2,3])
                elif (num_t==1):
                    dask_array = da.moveaxis(dask_array_raw,[channel_axis,scan_axis,y_axis,x_axis],[0,1,2,3])
            elif len(dataset_shape) == 3:
                dask_array = da.moveaxis(dask_array_raw,[scan_axis,y_axis,x_axis],[0,1,2])

            del dataset
            del dask_array_raw

        else:
            all_images = sorted(glob.glob(str(input_dir_path / '*.tif')))
            array_images = np.zeros((len(all_images), y_pixels,x_pixels), dtype=np.uint16)
            for idx, image in enumerate(all_images):
                array_images[idx] = skimage.io.imread(image)
            dask_array = da.squeeze(da.from_array(np.reshape(array_images,[num_t,num_ch,num_images,y_pixels,x_pixels]),chunks=[1,1,y_pixels,x_pixels]))

        # check if user provided output path
        if acq_type == 0:
            output_dir_path = input_dir_path.resolve().parents[0]
            # if (output_dir_string==''):
            #     output_dir_path = input_dir_path.resolve().parents[0]
            # else:
            #     output_dir_path = Path(output_dir_string)
        else:
            output_dir_path = input_dir_path
            # if (output_dir_string==''):
            #     output_dir_path = input_dir_path
            # else:
            #     output_dir_path = Path(output_dir_string)

        # https://github.com/nvladimus/npy2bdv
        # create BDV H5 file with sub-sampling for BigStitcher
        if decon_flag == 0 and flatfield_flag == 0:
            output_path = output_dir_path / 'full_deskew_only.h5'
        elif decon_flag == 0 and flatfield_flag == 1:
            output_path = output_dir_path / 'full_deskew_flatfield.h5'
        elif decon_flag == 1 and flatfield_flag == 0:
            output_path = output_dir_path / 'full_deskew_decon.h5'
        elif decon_flag == 1 and flatfield_flag == 1:
            output_path = output_dir_path / 'full_deskew_flatfield_decon.h5'

        bdv_writer = npy2bdv.BdvWriter(str(output_path), nchannels=num_ch, ntiles=1, subsamp=((1,1,1),),blockdim=((16, 16, 16),))

        # calculate pixel sizes of deskewed image in microns
        # Cannot use a different pixel size in (x,y) in BigStitcher, so calculate here for posterity
        deskewed_x_pixel = pixel_size / 1000.
        deskewed_y_pixel = pixel_size / 1000.
        deskewed_z_pixel = pixel_size / 1000.
        print('Deskewed pixel sizes before downsampling (nm). x='+str(deskewed_x_pixel)+', y='+str(deskewed_y_pixel)+', z='+str(deskewed_z_pixel)+'.')

        # set up parameters for deskew parameters
        deskew_parameters = np.empty([3])
        deskew_parameters[0] = theta             # (degrees)
        deskew_parameters[1] = scan_step         # (nm)
        deskew_parameters[2] = pixel_size        # (nm)

        # amount of down sampling in z
        z_down_sample = 1

        # create blank affine transformation to use for stage translation
        unit_matrix = np.array(((1.0, 0.0, 0.0, 0.0), # change the 4. value for x_translation (px)
                                (0.0, 1.0, 0.0, 0.0), # change the 4. value for y_translation (px)
                                (0.0, 0.0, 1.0, 0.0)))# change the 4. value for z_translation (px)

        # if retrospective flatfield is requested, import and open pyimagej in interactive mode
        # because BaSiC flat-fielding plugin cannot run in headless mode
        if flatfield_flag:
            from image_post_processing import manage_flat_field
            import imagej
            import scyjava
            from scyjava import jimport

            scyjava.config.add_option('-Xmx12g')
            plugins_dir = Path('/home/dps/Fiji.app/plugins')
            scyjava.config.add_option(f'-Dplugins.dir={str(plugins_dir)}')
            ij_path = Path('/home/dps/Fiji.app')
            ij = imagej.init(str(ij_path), headless=False)
            ij.ui().showUI()

        # if decon is requested, import microvolution wrapper
        # this file is private and does not follow the same license as the rest of our code.
        if decon_flag:
            from mvdecon import mv_decon

        # initialize tile counter
        tile_idx = 0
        timepoints_in_data = list(range(num_t))
        y_in_data = list(range(num_y))
        z_in_data = list(range(num_z))
        ch_in_BDV = list(range(n_active_channels))

        # loop over each directory. Each directory will be placed as a "tile" into the BigStitcher file
        for (t_idx, ch_BDV_idx) in product(timepoints_in_data,ch_in_BDV):

            ch_idx = channels_in_data[ch_BDV_idx]

            # pull data stack
            print('Process timepoint '+str(t_idx)+'; channel '+str(ch_BDV_idx) +'.')
            if (num_t == 1) and (num_ch==1):
                sub_stack = dask_array
            elif (num_t == 1) and not(num_ch==1):
                sub_stack = dask_array[ch_BDV_idx,:,:,:]
            elif not(num_t == 1) and (num_ch==1):
                sub_stack = dask_array[t_idx,:,:,:]
            elif not(num_t == 1) and not(num_ch==1):
                sub_stack = dask_array[t_idx,ch_BDV_idx,:,:,:]

            # perform
            #  flat-fielding
            if flatfield_flag == 0:
                corrected_stack=sub_stack.compute()
            else:
                print('Flatfield.')
                corrected_stack = manage_flat_field(sub_stack,ij)
            del sub_stack

            # deskew
            print('Deskew.')
            deskewed = deskew(data=np.flipud(corrected_stack),parameters=deskew_parameters)
            del corrected_stack

            # run deconvolution on deskewed image
            if decon_flag == 0:
                deskewed_decon = deskewed
            else:
                print('Deconvolve.')
                deskewed_decon = mv_decon(deskewed,ch_idx,deskewed_y_pixel,deskewed_z_pixel)
            del deskewed

            # downsample in z due to oversampling when going from OPM to coverslip geometry
            if z_down_sample==1:
                deskewed_downsample = deskewed_decon
            else:
                print('Downsample.')
                deskewed_downsample = block_reduce(deskewed_decon, block_size=(z_down_sample,1,1), func=np.mean)
            del deskewed_decon

            # save tile in BDV H5 with actual stage positions
            print('Write data into BDV H5.')
            bdv_writer.append_view(deskewed_downsample, time=t_idx, channel=ch_BDV_idx,
                                    tile=0,
                                    voxel_size_xyz=(deskewed_y_pixel, deskewed_y_pixel, z_down_sample*deskewed_z_pixel),
                                    voxel_units='um')

            # free up memory
            del deskewed_downsample

        # write BDV xml file
        # https://github.com/nvladimus/npy2bdv
        #bdv_writer.write_xml(ntimes=num_t)
        bdv_writer.write_xml()
        bdv_writer.close()

        # shut down pyimagej
        if flatfield_flag==1:
            ij.getContext().dispose()

    # exit
    print('Finished.')
    sys.exit()

# run
if __name__ == "__main__":
    main(sys.argv[1:])
    
