{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oligopaints based multiplexed RNA-FISH probe sequence design pipeline \n",
    "  \n",
    "The goal of this pipeline is to take a set of genes and use [OligoPaints](https://oligopaints.hms.harvard.edu/genome-files) for encoding probes, [DNA 20-mers](https://elledge.hms.harvard.edu/?page_id=638) for readout probes/primers, and [5x5 bDNA sequences](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-019-43943-8/MediaObjects/41598_2019_43943_MOESM2_ESM.xlsx) for signal amplification. Signal amplification is necessary because the number of probes for many of our genes of interest are significantly less than the 96 probes used in the original MERFISH papers. The rules for our pipeline are assembled from all of the various MERFISH publications by Rory Kruithoff.  \n",
    "  \n",
    "This pipeline can generate readout strategies using a) multiplex by sequential or b) multiplex by barcoding. For (a) the relative expression levels for target genes needs to be provided. For (b) the Hamming code strategy needs to be defined.\n",
    "  \n",
    "Written on Ubuntu 18.04 LTS (both native and using Windows Subsytem). This code requires a working local BLAST install, working local BEDtools install, and some work to get cruzdb running with Python 3.x. Will write up the install in an another markdown once everything is finalized.\n",
    "\n",
    "Current external dependencies:\n",
    "- local [BLAST install](https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/)\n",
    "- local [BEDTOOLS install](https://bedtools.readthedocs.io/en/latest/content/installation.html)\n",
    "  \n",
    "Current library dependencies:\n",
    "- python = 3.6\n",
    "- cruzdb (requires some effort to install in python 3.6, need to use [pull request 16](https://github.com/brentp/cruzdb/pull/16))\n",
    "- pandas\n",
    "- pybedtools\n",
    "- biopython  \n",
    "- numpy  \n",
    "- os  \n",
    "  \n",
    "Current external data dependencies:\n",
    "- hg38 OligoPaints BED files  \n",
    "- hg38 transcriptome fasta file  \n",
    "- hg38 ncRNA fasta file  \n",
    "- Elledge lab 240k list of 25-mer sequences\n",
    "- Zhuang lab modified hamming codes  \n",
    "- Wollman lab modified hamming codes\n",
    "- Moffitt lab standard readout sequences\n",
    "- Moffitt lab amplified readout sequences \n",
    "\n",
    "Douglas Shepherd, PhD  \n",
    "Quantitative Imaging and Inference Lab (qi2lab)  \n",
    "Center for Biological Physics and Department of Physics  \n",
    "Arizona State University  \n",
    "04.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define probe set parameters\n",
    "- readout strategy (sequential,barcode) AND (denovo, Moffitt, amplified)\n",
    "  - if sequential, need to define number of colors per round AND relative expression of genes\n",
    "  - if barcode, need to define hamming code set (14-bit,16-bit,18-bit,24-bit)\n",
    "- genome (hg38)\n",
    "  - TO DO: add support for rat and mouse)\n",
    "- genes of interest\n",
    "  - TO DO: add support for reading in from file or other pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define readout probe strategy\n",
    "readout_strategy = ['sequential','amplified']\n",
    "\n",
    "# if using multiplex by barcoding, define barcode strategy\n",
    "hamming_bit = '16-bit'\n",
    "\n",
    "# if using multiplex by sequential, define number of colors per round\n",
    "number_of_colors = 4\n",
    "\n",
    "# define target genome\n",
    "genome = 'hg38'\n",
    "\n",
    "# define target genes\n",
    "# use refGene ID is UCSC\n",
    "# TO DO: create function to parse & load output of gene selection software\n",
    "gene_ids=['CLDN5','PTPRC','PDGFRB','CDH1']\n",
    "\n",
    "# if using multiplex by sequential, define relative expression of genes by index from high to low\n",
    "relative_expression = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cruzdb imports\n",
    "# # https://github.com/brentp/cruzdb/tree/pull16/cruzdb\n",
    "from cruzdb import Genome \n",
    "\n",
    "# pandas imports\n",
    "# https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "# pybedtools imports\n",
    "# https://daler.github.io/pybedtools/\n",
    "# relies on a local BEDTOOLS installation\n",
    "import pybedtools \n",
    "\n",
    "# biopython imports\n",
    "# https://biopython.org/\n",
    "# relies on a local BLASTx installation\n",
    "from Bio import SeqIO\n",
    "from Bio import SearchIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.SeqUtils import GC as gcCheck\n",
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline as blastn\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "# numpy imports\n",
    "import numpy as np\n",
    "\n",
    "# os imports\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding probe design \n",
    "1. Define genes using refGene name from UCSC browser\n",
    "2. Pull all isoforms from UCSC associated with refGene name\n",
    "3. Parse out exons for each isoform.\n",
    "4. Using OligoPaints 'balanced' hg38 database to select probes for each isoform.\n",
    "5. Find unique probes that span all isoforms. Save probes in Pandas structure and a BLAST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take a dataframe of chromosome, exon locations, and strandness for one gene isoform and return a BED file \n",
    "def df_to_bed_isoform(gene_id,df_isoform):\n",
    "\n",
    "    # loop over each exon and create list of strings with format\n",
    "    # CHR START STOP NAME STRAND\n",
    "    bed_record=[]\n",
    "    i=0\n",
    "    for index, row in df_isoform.iterrows():\n",
    "        line=(str(row['chromosome']),str(row['start']),str(row['stop']),\n",
    "              gene_id+'_exon_'+str(row['exon']),0,str(row['strand']))\n",
    "        bed_record.append(line)\n",
    "        i+=1\n",
    "\n",
    "    # convert list of strings to BED record\n",
    "    BED_isoform = pybedtools.BedTool(bed_record)\n",
    "\n",
    "    # return BED record\n",
    "    return BED_isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to take an isoform and return a set of probes\n",
    "def find_probes_from_isoform(gene_id,df_isoform,isoform_number):\n",
    "    \n",
    "    # convert dataframe to BED record\n",
    "    BED_isoform = df_to_bed_isoform(gene_id,df_isoform)\n",
    "    \n",
    "    # load OligoPaints BED file corresponding to chromosome for gene\n",
    "    BED_all_probes =pybedtools.BedTool('oligodb/hg38b/hg38_'+str(df_isoform.chromosome.unique()[0]).split('_')[0]+'b.bed')\n",
    "    \n",
    "    # find probes using intersect\n",
    "    encoding_probes = BED_all_probes.intersect(BED_isoform,f=1)\n",
    "    \n",
    "    # turn output into a list of strings\n",
    "    # check if strand is + or -\n",
    "    # if +, store probe\n",
    "    # if -, take reverse complement before storing probe\n",
    "    encoding_probes_sequence = []\n",
    "    for interval in encoding_probes:\n",
    "        if df_isoform.strand.unique()[0]=='+':\n",
    "            encoding_probes_sequence.append(interval.name)\n",
    "        else:\n",
    "            temp_seq = Seq(interval.name, generic_dna)\n",
    "            encoding_probes_sequence.append(str(temp_seq.reverse_complement()))\n",
    "        \n",
    "    # convert list of strings into dataframe\n",
    "    i=0\n",
    "    df_isoform_probes = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "    for probe_seq in encoding_probes_sequence:\n",
    "        df_isoform_probes = df_isoform_probes.append({'gene': gene_id, 'isoform': isoform_number,'probe': i,\n",
    "                                             'sequence': probe_seq},ignore_index=True)\n",
    "        i+=1\n",
    "    \n",
    "    # return dataframe for probes for this gene\n",
    "    return df_isoform_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve exons from UCSC for a refGene ID\n",
    "def generate_encoding_probes(database, gene_ids):\n",
    "\n",
    "    # open connection to UCSC database\n",
    "    # here, we use the hg38 human genome assembly\n",
    "    g = Genome(db=genome)\n",
    "\n",
    "    # create empty dataframe to store all probes\n",
    "    df_encoding_probes = pd.DataFrame(columns=['gene','probe','sequence'])\n",
    "\n",
    "    # create empty dataframe\n",
    "    df_encoding_across_all_isoforms = pd.DataFrame(columns=['gene','isoform','probe','sequence'])\n",
    "\n",
    "    # loop over all genes\n",
    "    for gene_id in gene_ids:\n",
    "\n",
    "        # pull all entries for a given gene from UCSC\n",
    "        gene_entry_all = g.refGene.filter_by(name2=gene_id).all()\n",
    "\n",
    "        j=0\n",
    "        # loop over all gene entries\n",
    "        for isoform in gene_entry_all:\n",
    "\n",
    "            # extract exons for this gene entry\n",
    "            exons=isoform.exons\n",
    "\n",
    "            # create empty dataframe\n",
    "            df_exons = pd.DataFrame(columns=['gene','chromosome','exon','start','stop','strand'])\n",
    "\n",
    "            # place each exon in dataframe \n",
    "            i=0\n",
    "            for exon in exons:\n",
    "                df_exons = df_exons.append({'gene': gene_id, 'chromosome': isoform.chrom, \n",
    "                                           'exon': i, 'start': exon[0], 'stop': exon[1], 'strand': isoform.strand},\n",
    "                                          ignore_index=True)\n",
    "                i+=1\n",
    "\n",
    "            df_encoding_isoform=find_probes_from_isoform(gene_id,df_exons,j)\n",
    "            j+=1\n",
    "\n",
    "            df_encoding_across_all_isoforms = df_encoding_across_all_isoforms.append(df_encoding_isoform,ignore_index=True)\n",
    "\n",
    "    df_encoding_unique = df_encoding_across_all_isoforms.drop_duplicates(['sequence'])\n",
    "    df_encoding_unique=df_encoding_unique.reset_index()\n",
    "\n",
    "    # place this into the larger dataframe\n",
    "    df_encoding_probes=df_encoding_probes.append(df_encoding_unique,ignore_index=True)\n",
    "    df_encoding_probes=df_encoding_probes.drop(columns=['probe','index'])\n",
    "\n",
    "    return df_encoding_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse non-coding RNA FASTA\n",
    "1. [Download hg38 ncRNA fasta](ftp://ftp.ensembl.org/pub/release-99/fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz)\n",
    "2. Check if BLASTDB already created\n",
    "3. Parse out 'tRNA', 'Mt-tRNA', 'rRNA'\n",
    "4. Create blast database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_blastDB_ncRNA():\n",
    "    \n",
    "    if not(os.path.exists('/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa')):\n",
    "\n",
    "        records_to_keep=[]\n",
    "        with open('/home/dps/merfish/blastdb/tRNA/Homo_sapiens.GRCh38.ncrna.fa', 'r') as handle:\n",
    "            for record in SeqIO.parse(handle, 'fasta'):\n",
    "                description=record.description\n",
    "                if ('tRNA' in description) or ('rRNA' in description):\n",
    "                    records_to_keep.append(record)\n",
    "\n",
    "        with open('/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa','a') as output_handle:\n",
    "            for record in records_to_keep:\n",
    "                SeqIO.write(record,output_handle,'fasta')\n",
    "\n",
    "        cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/tRNA/tRNA_parsed.fa',\n",
    "                                           title='tRNA',out='/home/dps/merfish/blastdb/tRNA/db/tRNA')\n",
    "        stdout, stderr = cline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo readout probe design\n",
    "1. Create set of all potential 20-mer readout probes from [known set](https://doi.org/10.1073/pnas.0812506106) of 240,000 25-mers.\n",
    "2. Select probes with only 'A', 'T', and 'C'.\n",
    "3. Select probes without 'CCC', 'AAA', and 'TTT'.\n",
    "4. Select probes with 40-50% GC content.\n",
    "5. BLAST 20-mers against transcriptome for species of interest. Select those with less than 11 contiguous base homology.\n",
    "6. BLAST 20-mers aganist tRNA, rRNA for species of interest and mitochondria. Select those with less than 11 contiguous base homology.\n",
    "7. BLAST 20-mers against other selected 20-mers. Select those with less than 11 contiguous base homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_denovo_readout_probes():\n",
    "    \n",
    "    # Make sure non-coding RNA database exists\n",
    "    fasta_to_blastDB_ncRNA()\n",
    "    \n",
    "    big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "    big_list_25mers=[]\n",
    "    \n",
    "    for i in range(0,len(big_list_25mers_all)):\n",
    "        big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "        \n",
    "    K=20\n",
    "    big_list_20mers=[]\n",
    "        \n",
    "    for trial_25mer in big_list_25mers:\n",
    "        trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "        for trial_20mer in trial_20mers:\n",
    "            if not ('G' in trial_20mer):\n",
    "                #trial_20mer.replace('C','G')\n",
    "                big_list_20mers.append(trial_20mer)\n",
    "            \n",
    "    pass_list=[]\n",
    "    for probe in big_list_20mers:\n",
    "        if not (('CCC' in probe) or ('TTT' in probe) or ('AAA' in probe)):\n",
    "            pass_list.append(probe)\n",
    "                \n",
    "    pass_list2=[]\n",
    "    for probe in pass_list:\n",
    "        gc_count = gcCheck(probe)\n",
    "\n",
    "        if (gc_count>=40) and (gc_count<=50):\n",
    "            pass_list2.append(probe)\n",
    "    \n",
    "    pass_list3=[]\n",
    "    i=0\n",
    "    for probe in pass_list2:\n",
    "        \n",
    "        if (os.path.exists('readout_test_h3g8.fasta')):\n",
    "            os.remove('readout_test_h3g8.fasta')\n",
    "                \n",
    "        if(os.path.exists('readout_check_hg38.xml')):\n",
    "            os.remove('readout_check_hg38.xml')\n",
    "\n",
    "        with open('readout_test_h3g8.fasta','w') as output_handle:\n",
    "            record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "        i+=1\n",
    "        \n",
    "        blastn_cline = blastn(query='readout_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                              out='readout_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_hg38.xml','r') as input_handle_hg38:\n",
    "            blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list3.append(probe)\n",
    "            \n",
    "    pass_list4=[]\n",
    "    i=0\n",
    "    for probe in pass_list3:\n",
    "\n",
    "        if (os.path.exists('readout_test_ncRNA.fasta')):\n",
    "            os.remove('readout_test_ncRNA.fasta')\n",
    "                \n",
    "        if(os.path.exists('readout_check_ncRNA.xml')):\n",
    "            os.remove('readout_check_ncRNA.xml')\n",
    "        \n",
    "        with open('readout_test_ncRNA.fasta','w') as output_handle:\n",
    "            record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "        i+=1\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                              out='readout_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "            blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_ncRNA:\n",
    "            if (hit.seq_len>=10):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list4.append(probe)\n",
    "            \n",
    "            \n",
    "    if (os.path.exists('/home/dps/merfish/blastdb/readout/readout_candidates.fasta')):\n",
    "        os.remove('/home/dps/merfish/blastdb/readout/readout_candidates.fasta')\n",
    "            \n",
    "    i=0\n",
    "    with open('/home/dps/merfish/blastdb/readout/readout_candidates.fasta','a') as output_handle:\n",
    "        for probe in pass_list4:\n",
    "            record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description='potential_readout+'+str(i))\n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "            i+=1\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/readout/readout_candidates.fasta',\n",
    "                                       title='readout',out='/home/dps/merfish/blastdb/readout/db/readout')\n",
    "    stdout, stderr = cline()\n",
    "                \n",
    "    pass_list5=[]\n",
    "    i=0\n",
    "    for probe in pass_list4:\n",
    "\n",
    "        if (os.path.exists('readout_test_final.fasta')):\n",
    "            os.remove('readout_test_final.fasta')\n",
    "                \n",
    "        if(os.path.exists('readout_test_final.xml')):\n",
    "            os.remove('readout_test_final.xml')\n",
    "        \n",
    "        with open('readout_test_final.fasta','w') as output_handle:\n",
    "            record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i))\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "        i+=1\n",
    "                \n",
    "        blastn_cline = blastn(query='readout_test_final.fasta',db='/home/dps/merfish/blastdb/readout/db/readout',\n",
    "                              out='readout_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('readout_test_final.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=10) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list5.append(probe)\n",
    "    \n",
    "    # place each probe in dataframe \n",
    "    df_readout_probes = pd.DataFrame(columns=['probe','sequence'])\n",
    "    i=0\n",
    "    for probe in pass_list5:\n",
    "        df_readout_probes = df_readout_probes.append({'probe': i, 'sequence': probe},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_readout_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published standard readout sequences\n",
    "1. Load readout sequences used for 16-bit MHD4 code from [Moffitt et al 2018](https://doi.org/10.1073/pnas.1617699113).\n",
    "2. Need to use reverse complement of these when assembling probes.\n",
    "  \n",
    "Moffitt et al used 'A','T','G' instead of the 'A','T','C' strategy used for our denovo readout sequence design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moffitt_readout_sequences():\n",
    "    \n",
    "    df_readout = pd.read_csv('/home/dps/merfish/16bit_MHD4_readout.tsv',sep='\\t',header=0,index_col='probe')\n",
    "    df_readout.reset_index(inplace=True)\n",
    "    \n",
    "    return df_readout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published amplified readout sequences \n",
    "1. Load 5x5 amplified readout sequences for 16-bit MHD4 code from [Xia et al 2019](https://doi.org/10.1038/s41598-019-43943-8).\n",
    "2. Need to use reverse complement of original readout sequences when assembling probes.\n",
    "\n",
    "This is a clear area of opportunity. Look into orthogonal strategies used in [SABER](https://www.nature.com/articles/s41592-019-0404-0#Sec36). I agree with Moffitt that solid-phase amplifiers with defined number of binding sites makes more sense as it will reduce variation. Even if it does cost a little bit extra. Also, many groups I have talked to have not been able to successfully perform the SABER reaction to get amplifiers.  \n",
    "  \n",
    "For single shot multiplexing with amplification, we often use [HCR v3.0](https://www.molecularinstruments.com/hcr-v3). Since HCR v3.0 is also an unbounded amplification, it has similiar issues for quantification and usability for multiplex by barcoding. Given the known issues with seqFISH and seqFISH+, I'm hesistant to use HCR based strategies for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amplified_readout_sequences():\n",
    "    \n",
    "    df_readout_amplified = pd.read_excel('/home/dps/merfish/16bit_MHD4_amplify.xlsx',skip_row=0,header=1,index_col='Bit')\n",
    "    \n",
    "    return df_readout_amplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function to load selected readout probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_readout_probes(readout_strategy):\n",
    "    \n",
    "    if readout_strategy=='denovo':\n",
    "        df_readout_probes=generate_denovo_readout_probes()\n",
    "    elif readout_strategy=='standard':\n",
    "        df_readout_probes=load_moffitt_readout_sequences()\n",
    "    else:\n",
    "        df_readout_probes=load_amplified_readout_sequences()\n",
    "        \n",
    "    return df_readout_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper function to load selected Hamming codes\n",
    "Load:\n",
    "1. 14-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "2. 16-bit modified hamming codes from [Zhuang lab example data #1](http://zhuang.harvard.edu/merfish.html).\n",
    "3. 18-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).\n",
    "4. 24-bit modified hamming codes from [Wollman MERFISH github repo](https://github.com/wollmanlab/PySpots).  \n",
    "  \n",
    "This is a clear area of opportunity. We are working on alternative coding/decoding at ASU, but are not ready to roll it out yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hamming_codes(bit):\n",
    "\n",
    "    if (bit=='14-bit'):\n",
    "        list_hamming=[]\n",
    "        with open('/home/dps/merfish/codebook/14bit_MHD2_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13'])\n",
    "    elif (bit=='16-bit'):\n",
    "        list_hamming=[]\n",
    "        with open('/home/dps/merfish/codebook/16bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            for record in SeqIO.parse(input_handle, 'fasta'):\n",
    "                list_hamming.append(record.description.split())\n",
    "\n",
    "        df_hamming_codes=pd.DataFrame(list_hamming,columns=['R0','R1','R2','R3',\n",
    "                                                        'R4','R5','R6','R7',\n",
    "                                                        'R8','R9','R10','R11',\n",
    "                                                        'R12','R13','R14','R15'])\n",
    "        \n",
    "    elif (bit=='18-bit'):\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17'])\n",
    "        with open('/home/dps/merfish/codebook/18bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "                \n",
    "    else:\n",
    "        df_hamming_codes=pd.DataFrame(columns=['R0','R1','R2','R3',\n",
    "                                               'R4','R5','R6','R7',\n",
    "                                               'R8','R9','R10','R11',\n",
    "                                               'R12','R13','R14','R15',\n",
    "                                               'R16','R17','R18','R19',\n",
    "                                               'R20','R21','R22','R23'])\n",
    "        with open('/home/dps/merfish/codebook/24bit_MHD4_codebook.fasta','r') as input_handle:\n",
    "            df_hamming_codes=pd.read_csv(input_handle,delimeter=',')\n",
    "            \n",
    "    return df_hamming_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding + readout assembly using sequential labeling\n",
    "1. Create experiment specific codebook using four-colors, number of genes, and relative expression levels\n",
    "2. Sort genes into bins of 4 with different expression levels\n",
    "3. Assign highest expression to lowest efficiency channel on OPM (Cy7), second highest to channel with most autofluorescence (Alexa 488), third highest to Alexa 647, and lowest to Alexa 594.\n",
    "4. Save metadata and encoding+readout probes into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_readout_plus_encoding_sequential(df_readout,df_encoding,relative_expression,readout_type,number_of_colors):\n",
    "    \n",
    "    # determine number of rounds\n",
    "    gene_ids = df_encoding['gene'].unique()\n",
    "    number_of_genes=len(gene_ids)\n",
    "    number_of_rounds = number_of_genes/number_of_colors\n",
    "    \n",
    "    # sort genes based on relative expression (high -> low)\n",
    "    zipped_genes_expression = zip(relative_expression, gene_ids)\n",
    "    sorted_genes_expression = sorted(zipped_genes_expression)\n",
    "    sorted_genes = [element for _, element in sorted_genes_expression]\n",
    "    \n",
    "    # split genes into rounds \n",
    "    split_gene_ids=np.array_split(sorted_genes, number_of_colors)\n",
    "\n",
    "    # if using amplified readout, clean up to just have primary readouts\n",
    "    if readout_type == 'amplified':\n",
    "        cols=df_readout.columns\n",
    "        df_readout = df_readout.drop(columns=[str(cols[1]),str(cols[2]), str(cols[3])])\n",
    "        df_readout = df_readout.rename(columns={str(cols[0]): 'sequence'})\n",
    "        df_readout.reset_index(inplace=True)\n",
    "        \n",
    "    # create metadata dataframe\n",
    "    df_metadata = pd.DataFrame(columns=['gene','readout round','readout bit','readout dye'])\n",
    "\n",
    "    # create encoding+readout dataframe\n",
    "    df_encoding_readout = pd.DataFrame(columns=['probe','gene','sequence','isoform','readout round', 'readout bit', 'readout dye'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # assign highest expression across number of rounds, then repeat with next expression\n",
    "    # until rounds are full or genes are exhausted\n",
    "    \n",
    "    # in this strategy, we assign both readout flaps to the same readout sequence\n",
    "    readout_dyes=['alexa750','alexa488','alexa647','alexa594']\n",
    "    bit_counter = 0\n",
    "    \n",
    "    for gene_ids, readout_dye in zip(split_gene_ids,readout_dyes):\n",
    "        round_counter=0\n",
    "\n",
    "        for gene_id in gene_ids:\n",
    "            # extract encoding probes for this gene\n",
    "            df_gene = df_encoding[df_encoding['gene']==gene_id]\n",
    "            df_gene.reset_index(inplace=True)\n",
    "            \n",
    "            df_temp=pd.DataFrame(columns=['probe','gene','sequence','isoform','readout bit','readout dye'])\n",
    "        \n",
    "            number_of_probes = len(df_gene['sequence'].unique())\n",
    "            \n",
    "            for i in range(0,number_of_probes):\n",
    "                readout = Seq(df_readout['sequence'][np.int(bit_counter)], generic_dna)\n",
    "                df_temp=df_temp.append({'probe': i,\n",
    "                                        'gene': df_gene['gene'][i],\n",
    "                                        'sequence': str(readout.reverse_complement())\n",
    "                                        + 'A'+ df_gene['sequence'][i] + 'A'\n",
    "                                        + str(readout.reverse_complement()),\n",
    "                                        'isoform': df_gene['isoform'][i],\n",
    "                                        'readout round': round_counter,\n",
    "                                        'readout bit': bit_counter,\n",
    "                                        'readout dye': readout_dye},ignore_index=True)\n",
    "                # create metadata structure\n",
    "                df_metadata=df_metadata.append({'gene': gene_id, 'readout round': round_counter,\n",
    "                                                'readout bit': bit_counter, \n",
    "                                                'readout dye': readout_dye},ignore_index=True)\n",
    "            round_counter+=1\n",
    "            bit_counter+=1\n",
    "            df_encoding_readout = df_encoding_readout.append(df_temp)\n",
    "        \n",
    "            \n",
    "    df_encoding_readout.reset_index(inplace=True)\n",
    "    df_encoding_readout=df_encoding_readout.drop(columns=['index'])\n",
    "    \n",
    "    return df_encoding_readout, df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding + readout assembly using Hamming codes (aka codebook)\n",
    "1. Create experiment specific codebook using two-colors, number of genes, and selected Hamming codes.\n",
    "2. Assemble encoding and readout probes\n",
    "3. Save metadata and encoding+readout probes into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_readout_plus_encoding_barcoded(df_readout,df_encoding, df_hamming_codes, barcode_type, readout_type):\n",
    "    \n",
    "    # randomly assign genes to barcode sequences\n",
    "    number_of_barcode_seqs = len(df_hamming_codes)\n",
    "    gene_ids = df_encoding['gene'].unique()\n",
    "    number_of_genes=len(gene_ids)\n",
    "    barcode_seq_assignments=np.random.choice(number_of_barcode_seqs,number_of_genes,replace=False)\n",
    "    \n",
    "    if readout_type == 'amplified':\n",
    "        cols=df_readout.columns\n",
    "        df_readout = df_readout.drop(columns=[str(cols[1]),str(cols[2]), str(cols[3])])\n",
    "        df_readout = df_readout.rename(columns={str(cols[0]): 'sequence'})\n",
    "        df_readout.reset_index(inplace=True)\n",
    "\n",
    "    #create metadata\n",
    "    df_metadata = pd.DataFrame(columns=['gene','barcode ID','hamming type','readout type'])\n",
    "\n",
    "    df_encoding_readout = pd.DataFrame(columns=['probe','gene','sequence','isoform','readout 1','readout 2'])\n",
    "\n",
    "    # loop through all genes\n",
    "    for gene_id, assignment in zip(gene_ids,barcode_seq_assignments):\n",
    "\n",
    "        # load barcode sequence associated with this gene\n",
    "        bits = df_hamming_codes.iloc[assignment]\n",
    "\n",
    "        # extract encoding probes for this gene\n",
    "        df_gene = df_encoding[df_encoding['gene']==gene_id]\n",
    "        df_gene.reset_index(inplace=True)\n",
    "\n",
    "        # extract number of encoding probes and calculate halfway point\n",
    "        number_of_probes = len(df_gene['sequence'].unique())\n",
    "        halfway = number_of_probes//2\n",
    "\n",
    "        df_temp=pd.DataFrame(columns=['probe','gene','sequence','isoform','readout 1','readout 2'])\n",
    "\n",
    "        # loop over sequence\n",
    "        # place the first two bits on first half the probes (3' then 5')\n",
    "        # place the second two bits on second half the probes (3' then 5')\n",
    "        bit_placed=0\n",
    "        bit_counter=0\n",
    "        \n",
    "        for bit in bits:\n",
    "            if (np.int(bit)==1):\n",
    "                if bit_placed == 0:\n",
    "                    for i in range(0,halfway):\n",
    "                        readout = Seq(df_readout['sequence'][np.int(bit_counter)], generic_dna)\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': str(readout.reverse_complement())\n",
    "                                                    + 'A'+ df_gene['sequence'][i],\n",
    "                                                'isoform': df_gene['isoform'][i],\n",
    "                                                'readout 1': bit_counter,\n",
    "                                                'readout 2': ''},ignore_index=True)\n",
    "                    bit_placed=bit_placed+1\n",
    "                elif bit_placed == 1:\n",
    "                    for i in range(0,halfway):\n",
    "                        readout = Seq(df_readout['sequence'][np.int(bit_counter)], generic_dna)\n",
    "                        df_temp['sequence'][i]= df_temp['sequence'][i]+'A'+ str(readout.reverse_complement())\n",
    "                        df_temp['readout 2'][i]= bit_counter\n",
    "                    bit_placed=bit_placed+1\n",
    "                elif bit_placed == 2:\n",
    "                    for i in range(halfway,len(df_gene)):\n",
    "                        readout = Seq(df_readout['sequence'][np.int(bit_counter)], generic_dna)\n",
    "                        df_temp=df_temp.append({'probe': i,\n",
    "                                                'gene': df_gene['gene'][i], \n",
    "                                                'sequence': str(readout.reverse_complement())\n",
    "                                                    + 'A' + df_gene['sequence'][i],\n",
    "                                                 'isoform': df_gene['isoform'][i],\n",
    "                                                'readout 1': bit_counter,\n",
    "                                                'readout 2': ''}, ignore_index=True)\n",
    "                    bit_placed=bit_placed+1\n",
    "                else:\n",
    "                    for i in range(halfway,len(df_gene)):\n",
    "                        readout = Seq(df_readout['sequence'][np.int(bit_counter)], generic_dna)\n",
    "                        df_temp['sequence'][i]= df_temp['sequence'][i]+'A'+ str(readout.reverse_complement())\n",
    "                        df_temp['readout 2'][i]= bit_counter\n",
    "            bit_counter=bit_counter+1\n",
    "\n",
    "        df_encoding_readout = df_encoding_readout.append(df_temp)\n",
    "\n",
    "        # create metadata structure\n",
    "        df_metadata=df_metadata.append({'gene': gene_id, 'barcode ID': assignment,\n",
    "                                        'hamming type': barcode_type, 'readout type': readout_type},ignore_index=True)\n",
    "\n",
    "    df_encoding_readout.reset_index(inplace=True)\n",
    "    df_encoding_readout=df_encoding_readout.drop(columns=['index'])\n",
    "    \n",
    "    return df_encoding_readout, df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denovo primer design\n",
    "1. Read (or create) set of 20-mers from known set of 25-mers\n",
    "2. Select 20-mers that end in 'GX' or 'CX' or 'XG' or 'XC' (GC clamp)\n",
    "3. Select 20-mers that do not contain triplet nucleotides\n",
    "4. Select 20-mers that have 50-65% GC\n",
    "5. Select 20-mers with Tm between 70 and 72C at 390 mM salt\n",
    "6. BLAST 20-mers against lincRNA, rRNA, tRNA, mt-tRNA, mt-RNA for species of interest. Select all probes with less than 8 hits.\n",
    "7. BLAST 20-mers against other 20-mers. Select all probes with less than 8 hits.\n",
    "8. BLAST 20-mers against encoding+readout probes. Select all probes with less than 8 hits.\n",
    "9. Select forward and reverse primer based on minimum number of off-target hits.\n",
    "10. Save primers into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_primers(df_probes):\n",
    "    \n",
    "    # Make sure non-coding RNA database exists\n",
    "    fasta_to_blastDB_ncRNA()\n",
    "\n",
    "    if not(os.path.exists('/home/dps/merfish/verified_primers.csv')):\n",
    "        big_list_25mers_all = list(SeqIO.parse('bc25mer.240k.fasta','fasta'))\n",
    "        big_list_25mers=[]\n",
    "\n",
    "        for i in range(0,len(big_list_25mers_all)):\n",
    "            big_list_25mers.append(str(big_list_25mers_all[i].seq))\n",
    "\n",
    "        K=20\n",
    "        big_list_20mers=[]\n",
    "\n",
    "        # Truncate 25-mers into 20-mers that have GC clamp\n",
    "        for trial_25mer in big_list_25mers:\n",
    "            trial_20mers = [trial_25mer[i: j] for i in range(len(trial_25mer)) for j in range(i + 1, len(trial_25mer) + 1) if len(trial_25mer[i:j]) == K]\n",
    "            for trial_20mer in trial_20mers:\n",
    "                if (trial_20mer.endswith('G') or trial_20mer.endswith('C') \n",
    "                    or str(trial_20mer[:-1]).endswith('G') or str(trial_20mers[:-1]).endswith('C')):\n",
    "                        big_list_20mers.append(trial_20mer)\n",
    "\n",
    "        # Check for triplets\n",
    "        pass_list=[]\n",
    "        for primer in big_list_20mers:\n",
    "            if not (('CCC' in primer) or ('TTT' in primer) or ('AAA' in primer) or ('GGG' in primer)):\n",
    "                pass_list.append(primer)\n",
    "\n",
    "        # Check GC content\n",
    "        pass_list2=[]\n",
    "        for primer in pass_list:\n",
    "            gc_count = gcCheck(primer)\n",
    "            if (gc_count>=50) and (gc_count<=65):\n",
    "                pass_list2.append(primer)\n",
    "\n",
    "        # Check melting temperature\n",
    "        pass_list3=[]\n",
    "        for primer in pass_list2:\n",
    "            tmval = mt.Tm_NN(primer,Na=390,dnac1=25,dnac2=0)        \n",
    "            if (tmval>=70.0) and (tmval<72.0):\n",
    "                    pass_list3.append(primer)\n",
    "\n",
    "        # BLAST against transcriptome\n",
    "        pass_list4=[]\n",
    "        i=0\n",
    "        for primer in pass_list3:\n",
    "\n",
    "            if (os.path.exists('primer_test_h3g8.fasta')):\n",
    "                os.remove('primer_test_h3g8.fasta')\n",
    "                \n",
    "            if(os.path.exists('primer_check_hg38.xml')):\n",
    "                os.remove('primer_check_hg38.xml')\n",
    "\n",
    "            with open('primer_test_h3g8.fasta','w') as output_handle:\n",
    "                record = SeqRecord(Seq(primer,generic_dna),id='primer_'+str(i))\n",
    "                SeqIO.write(record,output_handle,'fasta')\n",
    "            i+=1\n",
    "\n",
    "            blastn_cline = blastn(query='primer_test_h3g8.fasta',db='/home/dps/merfish/blastdb/hg38/GRCh38',\n",
    "                                  out='primer_check_hg38.xml',dust='no',word_size=10,outfmt=5)\n",
    "            stdout,stderr = blastn_cline()\n",
    "\n",
    "            with open('primer_check_hg38.xml','r') as input_handle_hg38:\n",
    "                blast_qresult = SearchIO.read(input_handle_hg38, 'blast-xml')\n",
    "\n",
    "            flagged=True\n",
    "\n",
    "            for hit in blast_qresult:\n",
    "                if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                    flagged=False\n",
    "                    break\n",
    "\n",
    "            if flagged:\n",
    "                pass_list4.append(primer)\n",
    "\n",
    "        # BLAST against non-coding RNA database\n",
    "        pass_list5=[]\n",
    "        i=0\n",
    "        for primer in pass_list4:\n",
    "\n",
    "            if (os.path.exists('primer_test_ncRNA.fasta')):\n",
    "                os.remove(\"primer_test_ncRNA.fasta\")\n",
    "                \n",
    "            if(os.path.exists('primer_check_ncRNA.xml')):\n",
    "                os.remove('primer_check_ncRNA.xml')\n",
    "            \n",
    "            with open('primer_test_ncRNA.fasta','w') as output_handle:\n",
    "                record = SeqRecord(Seq(primer,generic_dna),id='primer_'+str(i))\n",
    "                SeqIO.write(record,output_handle,'fasta')\n",
    "            i+=1\n",
    "\n",
    "            blastn_cline = blastn(query='primer_test_ncRNA.fasta',db='/home/dps/merfish/blastdb/tRNA/db/tRNA',\n",
    "                                  out='primer_check_ncRNA.xml',dust='no',word_size=10,outfmt=5)\n",
    "            stdout,stderr = blastn_cline()\n",
    "\n",
    "            with open('primer_check_ncRNA.xml','r') as input_handle_ncRNA:\n",
    "                blast_qresult_ncRNA = SearchIO.read(input_handle_ncRNA, 'blast-xml')\n",
    "\n",
    "            flagged=True\n",
    "\n",
    "            for hit in blast_qresult_ncRNA:\n",
    "                if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                    flagged=False\n",
    "                    break\n",
    "\n",
    "            if flagged:\n",
    "                pass_list5.append(primer)\n",
    "\n",
    "        # create BLASTDB for remaining primers\n",
    "        if (os.path.exists('/home/dps/merfish/blastdb/primer/primer_candidates.fasta')):\n",
    "                os.remove(\"/home/dps/merfish/blastdb/primer/primer_candidates.fasta\")\n",
    "        \n",
    "        i=0\n",
    "        with open('/home/dps/merfish/blastdb/primer/primer_candidates.fasta','a') as output_handle:   \n",
    "            for primer in pass_list5:\n",
    "                record = SeqRecord(Seq(primer,generic_dna),id=primer+'_'+str(i),description=\"potential_primer_\"+str(i))\n",
    "                SeqIO.write(record,output_handle,\"fasta\")\n",
    "                i+=1\n",
    "\n",
    "        cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='/home/dps/merfish/blastdb/primer/primer_candidates.fasta',\n",
    "                                           title='primer',out='/home/dps/merfish/blastdb/primer/db/primer')\n",
    "        stdout, stderr = cline()\n",
    "\n",
    "        # BLAST against remaining primer list\n",
    "        pass_list6=[]\n",
    "        i=0\n",
    "        for primer in pass_list5:\n",
    "            if (os.path.exists('primer_test_final.fasta')):\n",
    "                os.remove(\"primer_test_final.fasta\")\n",
    "                \n",
    "            if(os.path.exists('primer_test_final.xml')):\n",
    "                os.remove('primer_test_final.xml')\n",
    "            \n",
    "            with open('primer_test_final.fasta','w') as output_handle:\n",
    "                record = SeqRecord(Seq(primer,generic_dna),id='primer_'+str(i))\n",
    "                SeqIO.write(record,output_handle,'fasta')\n",
    "            i+=1\n",
    "\n",
    "            blastn_cline = blastn(query='primer_test_final.fasta',db='/home/dps/merfish/blastdb/primer/db/primer',\n",
    "                                  out='primer_test_final.xml',dust='no',word_size=10,outfmt=5)\n",
    "            stdout,stderr = blastn_cline()\n",
    "\n",
    "            with open('primer_test_final.xml','r') as input_handle_final:\n",
    "                blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "\n",
    "            flagged=True\n",
    "\n",
    "            for hit in blast_qresult_final:\n",
    "                if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                    flagged=False\n",
    "                    break\n",
    "\n",
    "            if flagged:\n",
    "                pass_list6.append(primer)\n",
    "                \n",
    "        # create dataframe\n",
    "        df_checked_primers = pd.DataFrame(columns=['primer','sequence'])\n",
    "        i=0\n",
    "        for primers in pass_list6:\n",
    "            df_checked_primers = df_checked_primers.append({'primer': i, 'sequence': primers},ignore_index=True)\n",
    "            i+=1\n",
    "        with open('/home/dps/merfish/verified_primers.csv','w') as output_handle:\n",
    "            df_checked_primers.to_csv(output_handle,index=False)\n",
    "        \n",
    "    else:\n",
    "        with open('/home/dps/merfish/verified_primers.csv','r') as input_handle:\n",
    "            df_checked_primers = pd.read_csv(input_handle)\n",
    "            \n",
    "        pass_list6 = df_checked_primers['sequence']\n",
    "        \n",
    "    # Create BLASTDB for encoding+readout probe constructs    \n",
    "    if (os.path.exists('probe_list.fasta')):\n",
    "        os.remove(\"probe_list.fasta\")\n",
    "        \n",
    "    extracted_probes = df_probes[\"sequence\"]\n",
    "    \n",
    "    i=0\n",
    "    with open('probe_list.fasta','w') as output_handle:   \n",
    "        for probe in extracted_probes:\n",
    "            record = SeqRecord(Seq(probe,generic_dna),id=probe+'_'+str(i),description=\"probe_\"+str(i)) \n",
    "            SeqIO.write(record,output_handle,\"fasta\")\n",
    "            i+=1\n",
    "\n",
    "    cline = NcbimakeblastdbCommandline(dbtype='nucl',input_file='probe_list.fasta',\n",
    "                                       title='probes',out='/home/dps/merfish/blastdb/probes/db/probes')\n",
    "    stdout, stderr = cline()\n",
    "    \n",
    "    # BLAST against encoding+readout probe constructs\n",
    "    pass_list7=[]\n",
    "    i=0\n",
    "    for primer in pass_list6:\n",
    "\n",
    "        if (os.path.exists('primer_test_probes.fasta')):\n",
    "            os.remove(\"primer_test_probes.fasta\")\n",
    "            \n",
    "        if(os.path.exists('primer_test_probes.xml')):\n",
    "                os.remove('primer_test_probes.xml')\n",
    "        \n",
    "        with open('primer_test_probes.fasta','w') as output_handle:\n",
    "            record = SeqRecord(Seq(primer,generic_dna),id='primer_'+str(i))\n",
    "            SeqIO.write(record,output_handle,'fasta')\n",
    "        i+=1\n",
    "                \n",
    "        blastn_cline = blastn(query='primer_test_probes.fasta',db='/home/dps/merfish/blastdb/probes/db/probes',\n",
    "                              out='primer_test_probes.xml',dust='no',word_size=10,outfmt=5)\n",
    "        stdout,stderr = blastn_cline()\n",
    "        \n",
    "        with open('primer_test_probes.xml','r') as input_handle_final:\n",
    "            blast_qresult_final = SearchIO.read(input_handle_final, 'blast-xml')\n",
    "        \n",
    "        flagged=True\n",
    "\n",
    "        for hit in blast_qresult_final:\n",
    "            if (hit.seq_len>=8) and (hit.seq_len<20):\n",
    "                flagged=False\n",
    "                break\n",
    "                \n",
    "        if flagged:\n",
    "            pass_list7.append(primer)\n",
    "            \n",
    "    # place final primers into a dataframe\n",
    "    df_final_primers = pd.DataFrame(columns=['primer','sequence'])\n",
    "    i=0\n",
    "    for primers in pass_list7:\n",
    "        df_final_primers = df_final_primers.append({'primer': i, 'sequence': primers},ignore_index=True)\n",
    "        i+=1\n",
    "        \n",
    "    return df_final_primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add primers, T7 promoter, and linkers to encoding + readout probe sequences for ordering\n",
    "- 5' - forward primer -'a'- readout 1 -'a'- encoding -'a'- readout 2 -'a'- T7 -'a'- reverse primer - 3'\n",
    "- when constructing, make sure that no triplet sequences are introduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_full_probes(df_encodingreadout,df_primers):\n",
    "    \n",
    "    # extract two random primers\n",
    "    primer_assignments=np.random.choice(len(df_primers),2,replace=False)\n",
    "    primer_01 = primer_assignments[0]\n",
    "    primer_02 = primer_assignments[1]\n",
    "    \n",
    "    # T7 promoter sequence\n",
    "    T7_sequence = 'TAATACGACTCACTATAGGG'\n",
    "    \n",
    "    df_fullprobes = pd.DataFrame(columns=['probe','gene','sequence','isoform'])\n",
    "    \n",
    "    for i in range(0,len(df_encodingreadout)):\n",
    "        df_fullprobes=df_fullprobes.append({'probe': i,\n",
    "                                            'gene': df_encodingreadout['gene'][i],\n",
    "                                            'sequence': df_primers['sequence'][primer_01] + 'A'\n",
    "                                            + df_encodingreadout['sequence'][i] + 'A'\n",
    "                                            + T7_sequence + 'A'\n",
    "                                            + df_primers['sequence'][primer_02],\n",
    "                                            'isoform': df_encodingreadout['isoform'][i]},\n",
    "                                            ignore_index=True)\n",
    "    \n",
    "    df_primer_choice = pd.DataFrame(columns=['index','sequence'])\n",
    "    df_primer_choice = df_primer_choice.append({'index': 0, \n",
    "                                                'sequence': df_primers['sequence'][primer_01]},\n",
    "                                               ignore_index=True)\n",
    "    df_primer_choice = df_primer_choice.append({'index': 1, \n",
    "                                                'sequence': df_primers['sequence'][primer_02]},\n",
    "                                               ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return df_fullprobes, df_primer_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run probe design pipeline\n",
    "1. Generate encoding probes for specified genes\n",
    "2. Load requested readout probes\n",
    "3. Generate encoding+readout probes for requested strategy\n",
    "4. Generate primers (can be slow if pre-screened database does not exist already)\n",
    "5. Generate full probes for ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['CLDN5'], dtype='<U6'), array(['PTPRC'], dtype='<U6'), array(['PDGFRB'], dtype='<U6'), array(['CDH1'], dtype='<U6')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dps/miniconda3/envs/merfish/lib/python3.6/site-packages/Bio/SearchIO/BlastIO/blast_xml.py:364: BiopythonParserWarning: Renaming hit ID '' to a BLAST-generated ID 'gnl|BL_ORD_ID|9' since the ID was already matched by your query 'primer_1718'. Your BLAST database may contain duplicate entries.\n",
      "  BiopythonParserWarning,\n"
     ]
    }
   ],
   "source": [
    "# generate encoding probe sequences\n",
    "df_encoding_probes = generate_encoding_probes(genome,gene_ids)\n",
    "\n",
    "# load (or generate) readout probe sequences\n",
    "df_readout_probes = load_readout_probes(readout_strategy[1])\n",
    "\n",
    "# generate multiplex by sequential readout + encoding\n",
    "if readout_strategy[0]=='sequential':\n",
    "    df_encoding_readout_probes, df_metadata = generate_readout_plus_encoding_sequential(df_readout_probes,\n",
    "                                                                                        df_encoding_probes,\n",
    "                                                                                        relative_expression,\n",
    "                                                                                        readout_strategy[1],\n",
    "                                                                                        number_of_colors)\n",
    "# generate multiplex by barcoding readout + encoding\n",
    "else:\n",
    "    df_barcodes = loadHammingFromDisk(hamming_bit)\n",
    "    # generate encoding+readout probe sequences using codebook\n",
    "    df_encoding_readout_probes, df_metadata = generateReadoutPlusEncoding(df_readout_probes,\n",
    "                                                                          df_encoding_probes,\n",
    "                                                                          df_barcodes,\n",
    "                                                                          hamming_bit,\n",
    "                                                                          readout_strategy[1])\n",
    "\n",
    "# generate forward and reverse primer sequences for this set of encoding+readout probes\n",
    "df_primers = generate_primers(df_encoding_readout_probes)\n",
    "\n",
    "# generate full probe sequences for ordering\n",
    "df_full_probes, df_primer_choice = construct_full_probes(df_encoding_readout_probes,df_primers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all dataframes to disk with unique identifier and all settings needed to regenerate workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull date\n",
    "# TO DO: look into better identifier method\n",
    "d = datetime.now()\n",
    "prefix = d.isoformat()\n",
    "\n",
    "# write encoding probes\n",
    "encoding_file = prefix+'encoding_probes.csv'\n",
    "with open(encoding_file,'w') as output_handle:\n",
    "    df_encoding_probes.to_csv(output_handle,index=False)\n",
    "    \n",
    "# write readout probes\n",
    "readout_file = prefix+'readout_file.csv'\n",
    "with open(readout_file,'w') as output_handle:\n",
    "    df_readout_probes.to_csv(output_handle,index=False)\n",
    "\n",
    "# write readout probes\n",
    "encoding_readout_file = prefix+'encoding_readout_file.csv'\n",
    "with open(encoding_readout_file,'w') as output_handle:\n",
    "    df_encoding_readout_probes.to_csv(output_handle,index=False)\n",
    "    \n",
    "# write hamming codes\n",
    "if readout_strategy[0]=='barcode':\n",
    "    hamming_file = prefix+'hamming_file.csv'\n",
    "    with open(hamming_file,'w') as output_handle:\n",
    "        df_barcodes.to_csv(output_handle,index=False)\n",
    "    \n",
    "# write primers\n",
    "primer_file = prefix+'primer_file.csv'\n",
    "with open(primer_file,'w') as output_handle:\n",
    "    df_primer_choice.to_csv(output_handle,index=False)\n",
    "    \n",
    "# write full probes (T7, primers, encoding, readout)\n",
    "fullprobes_file = prefix+'fullprobes_file.csv'\n",
    "with open(fullprobes_file,'w') as output_handle:\n",
    "    df_full_probes.to_csv(output_handle,index=False)\n",
    "    \n",
    "# write metadata\n",
    "metadata_file = prefix+'metadata_file.csv'\n",
    "with open(metadata_file,'w') as output_handle:\n",
    "    df_metadata.to_csv(output_handle,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "Copyright (c) 2020 Douglas Shepherd\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
